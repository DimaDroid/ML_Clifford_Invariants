{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fb953a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53b1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model, train function, evaluate function\n",
    "\n",
    "def build_model(input_shape, output_shape):\n",
    "    model = models.Sequential([\n",
    "    tf.keras.layers.Input(input_shape),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(output_shape)\n",
    "])\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_data, train_labels, epochs=10, batch_size=32):\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    history = model.fit(train_data, train_labels, epochs=epochs, batch_size=batch_size)\n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, test_data, test_labels):\n",
    "    loss = model.evaluate(test_data, test_labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b65d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data \n",
    "#separate into 9 datasets for 9 invariants assoicated with each permutation\n",
    "\n",
    "filepath = '' #for data\n",
    "\n",
    "perm_enc = []  \n",
    "\n",
    "data_list1 = []\n",
    "data_list2 = []\n",
    "data_list3 = []\n",
    "data_list4 = []\n",
    "data_list5 = []\n",
    "data_list6 = []\n",
    "data_list7 = []\n",
    "data_list8 = []\n",
    "data_list9 = []\n",
    "\n",
    "with open(filepath, 'r') as f:\n",
    "    datalist = []\n",
    "    for line in f.readlines()[1:]:\n",
    "        datalist.append([list(t) for t in eval(line)])\n",
    "\n",
    "len(datalist[0][1][0]) #check number of coefficients for each invariant is 256\n",
    "\n",
    "for i in range(len(datalist)):\n",
    "    perm= datalist[i][0]\n",
    "\n",
    "    num_elements = len(perm)\n",
    "    one_hot_perm = np.zeros((num_elements, num_elements))\n",
    "    for j, elem in enumerate(perm):\n",
    "        one_hot_perm[j, elem] = 1\n",
    "    perm_enc.append(one_hot_perm.reshape(64,))\n",
    "\n",
    "    coeff_list_i = datalist[i][1]\n",
    "    data_list1.append(coeff_list_i[0])\n",
    "    data_list2.append(coeff_list_i[1])\n",
    "    data_list3.append(coeff_list_i[2])\n",
    "    data_list4.append(coeff_list_i[3])\n",
    "    data_list5.append(coeff_list_i[4])\n",
    "    data_list6.append(coeff_list_i[5])\n",
    "    data_list7.append(coeff_list_i[6])\n",
    "    data_list8.append(coeff_list_i[7])\n",
    "    data_list9.append(coeff_list_i[8])\n",
    "\n",
    "data_list_9 = [data_list1,data_list2,data_list3,data_list4,data_list5,data_list6,data_list7,data_list8,data_list9]\n",
    "\n",
    "#collect subinvariants for each invariant i\n",
    "collected = []\n",
    "\n",
    "for list in data_list_9:\n",
    "    coeffall = []\n",
    "    coeff0 = []\n",
    "    coeff2 = []\n",
    "    coeff4 = []\n",
    "    coeff6 = []\n",
    "    coeff8 = []\n",
    "    for i in range(len(perm_enc)):\n",
    "        coeffall.append(list[i])\n",
    "        coeff0.append([list[i][0]])\n",
    "        coeff2.append(list[i][9:37])\n",
    "        coeff4.append(list[i][93:163])\n",
    "        coeff6.append(list[i][219:247])\n",
    "        coeff8.append([list[i][255]])\n",
    "    collected.append([coeffall,coeff0,coeff2,coeff4,coeff6,coeff8])\n",
    "\n",
    "\n",
    "select = [1,2,3,4,5,4,3,2,1] #only use non-zero subinvariants\n",
    "\n",
    "data_size = len(perm_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5adccd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists to store final accuracies and gradients\n",
    "finalacc = []\n",
    "finalgradient = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1542e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression: input permutation, output invariant/subinvariant, for each invariant 0-8\n",
    "\n",
    "for i in range(0,9): \n",
    "    print(f'Invariant: {i}')  #inv i\n",
    "\n",
    "    allcoeff = collected[i]\n",
    "\n",
    "    k = 5 \n",
    "    d = -2\n",
    "\n",
    "    finalaccfori = [] #collect the acc for full inv + subinvariants\n",
    "    #errors = []\n",
    "\n",
    "    #grad_all = []\n",
    "    avegradfori = [] #collect the mean grad for full inv + subinvariants\n",
    "\n",
    "    #for full invariant and each non-zero subinvariant\n",
    "    for coeff in allcoeff[:select[i]+1]: \n",
    "\n",
    "        print(f'{d}-vector') # subinv d, use -2 for the full invariant\n",
    "\n",
    "        # ave over 100 rounds of training\n",
    "\n",
    "        grad_all = []\n",
    "        acc_all = []\n",
    "\n",
    "        for loop in range(100): \n",
    "\n",
    "            ML_data = [[perm_enc[index],coeff[index]] for index in range(data_size)]\n",
    "            \n",
    "            np.random.shuffle(ML_data) \n",
    "\n",
    "            tl = int(0.8 * data_size)- int(0.8 * data_size) % k\n",
    "            dataset, final_test_dataset = ML_data[:tl], ML_data[tl:]\n",
    "            s = int(np.floor(len(dataset)/k))\n",
    "\n",
    "            Training_inputs, Training_outputs, Testing_inputs, Testing_outputs = [], [], [], []\n",
    "            for j in range(k):\n",
    "                Training_inputs.append([datapoint[0] for datapoint in dataset[:j*s]]+[datapoint[0] for datapoint in dataset[(j+1)*s:]])\n",
    "                Training_outputs.append([datapoint[1] for datapoint in dataset[:j*s]]+[datapoint[1] for datapoint in dataset[(j+1)*s:]])\n",
    "                Testing_inputs.append([datapoint[0] for datapoint in dataset[j*s:(j+1)*s]])\n",
    "                Testing_outputs.append([datapoint[1] for datapoint in dataset[j*s:(j+1)*s]])\n",
    "                \n",
    "        \n",
    "            input_shape = (64,)\n",
    "            output_shape = len(coeff[0])\n",
    "\n",
    "            model = build_model(input_shape, output_shape)\n",
    "\n",
    "            testloss = []\n",
    "\n",
    "            for fold in range(k):\n",
    "                print(f'Fold {fold+1}/{k}')\n",
    "\n",
    "                history = train_model(model, np.array(Training_inputs)[fold], np.array(Training_outputs)[fold], epochs=10, batch_size=32)\n",
    "                print('...trained')\n",
    "\n",
    "                test_loss = evaluate_model(model, np.array(Testing_inputs)[fold], np.array(Testing_outputs)[fold])\n",
    "                testloss.append(test_loss)\n",
    "                print(f'Test Loss: {test_loss:.4f}')\n",
    "            \n",
    "            #print(f'Invariant: {i}, {d}-vector, Test Loss: {np.mean(testloss):.4f} Â± {np.std(testloss):.4f}')\n",
    "            \n",
    "            #test with unseen data\n",
    "            finalTesting_inputs, finalTesting_outputs = [], []\n",
    "\n",
    "            for datapoint in final_test_dataset:\n",
    "                finalTesting_outputs.append(datapoint[1])\n",
    "                finalTesting_inputs.append(datapoint[0])\n",
    "\n",
    "            finaltest_loss = evaluate_model(model,np.array(finalTesting_inputs), np.array(finalTesting_outputs))\n",
    "            print(f'Invariant: {i}, {d}-vector, Final Test Loss: {finaltest_loss:.4f}')   \n",
    "\n",
    "            #calculate the accuracy after rounding the prediction to nearest integer\n",
    "            Pred = model.predict(np.array(finalTesting_inputs))\n",
    "            count = []\n",
    "            roundPred = []\n",
    "            correct = []\n",
    "            result = []\n",
    "            errorposition = []\n",
    "            for m in range(len(np.array(finalTesting_outputs))):\n",
    "                rounded_list = [round(elem) for elem in Pred[m] ]\n",
    "                #rounded_list = [round(elem*2)/2 for elem in Pred[m]]\n",
    "                roundPred.append(np.array(rounded_list))\n",
    "                if rounded_list == np.array(finalTesting_outputs[m]).tolist():\n",
    "                    count.append(1)\n",
    "                else:\n",
    "                    positionenc = finalTesting_inputs[m].reshape(8,8)\n",
    "                    position = []\n",
    "                    for row in positionenc:\n",
    "                        for l in range(8):\n",
    "                            if row[l] == 1:\n",
    "                                position.append(l)\n",
    "                    errorposition.append(position)\n",
    "                res = np.array(rounded_list)==np.array(finalTesting_outputs[m])\n",
    "                cor = sum(np.array(rounded_list)==np.array(finalTesting_outputs[m]))\n",
    "                correct.append(cor)\n",
    "                result.append(res)\n",
    "            accs1 = np.sum(count)/len(np.array(finalTesting_outputs))\n",
    "            #accs2 = np.sum(correct)/len(np.concatenate(finalTesting_outputs))\n",
    "            \n",
    "            acc_all.append(accs1)\n",
    "            #errors.append(errorposition)\n",
    "\n",
    "            #gradient saliency for each of the 100 loops\n",
    "            image = tf.Variable(finalTesting_inputs)\n",
    "            with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "                tape.watch(image)\n",
    "                predictions = model(image)\n",
    "                loss = predictions\n",
    "            \n",
    "            gradient = tape.gradient(loss, image)\n",
    "            gradient = gradient.numpy()\n",
    "            avg_grad = np.absolute(np.mean(gradient,axis=0)).reshape(1,64)\n",
    "            avg_grad_8 = []\n",
    "            for r in range(1,9):\n",
    "                a = np.mean(np.absolute(np.mean(gradient,axis=0))[8*(r-1):8*r])\n",
    "                avg_grad_8.append(a)\n",
    "            avg_grad_8 = np.array(avg_grad_8).reshape(1,8)\n",
    "            grad_all.append(avg_grad_8)\n",
    "\n",
    "            \n",
    "        #calculate the average gradients and accuracies\n",
    "        avegrad = np.mean(grad_all,axis = 0) \n",
    "        avegradfori.append(avegrad)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(avegrad,aspect='auto')\n",
    "        plt.savefig('D8_'+str(i)+str(d)+'_ave.png',bbox_inches='tight')\n",
    "\n",
    "        finalaccfori.append(np.mean(acc_all))\n",
    "\n",
    "        d = d+2 \n",
    "        \n",
    "\n",
    "    finalgradient.append(avegradfori)\n",
    "    finalacc.append(finalaccfori)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7439ed8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
